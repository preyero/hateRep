{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Semantic annotation of target groups\n",
    "\n",
    "This notebook process the data to present relevant background knowledge, by hyperlinking entities to the text and providing definitions > export data_preproc/sample.csv\n",
    "\n",
    "The file contains (in italics, the semantic annotations in output database.csv):\n",
    "\n",
    "An enriched text field:\n",
    "- *Text*\n",
    "- Stem_text: list of stem words on text\n",
    "- *match_URLs*: list of entity URLs in the text position.\n",
    "\n",
    "A semantic box:\n",
    "- Box_entity: label of the entities found in the text.\n",
    "- *Box_def*: corresponding definitions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import owlready2\n",
    "\n",
    "out_path = os.path.join('data_preproc')\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook will export: ['dataset', 'comment_id', 'text', 'box_entity', 'box_def', 'stem_text', 'match_URLs', 'match_entities', 'mismatch_entities', 'match_entities_init', 'entity_id']\n"
     ]
    }
   ],
   "source": [
    "# args\n",
    "cols_out = ['dataset', 'comment_id', 'text', 'box_entity', 'box_def', 'stem_text', \n",
    "    'match_URLs', 'match_entities', 'mismatch_entities', 'match_entities_init', 'entity_id']\n",
    "\n",
    "pred_cols = [f'target_gso_{f}' for f in ['Pred', 'IRI', 'Label', 'Def']]\n",
    "cols_in = ['comment_id', 'predict_text', 'dataset'] + pred_cols\n",
    "\n",
    "print('This notebook will export: {}'.format(cols_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHS\n",
      "130 texts from path: data_selection/mhs_fp.csv\n",
      "GABHATECORPUS\n",
      "84 texts from path: data_selection/gabhatecorpus_fp.csv\n",
      "HATEXPLAIN\n",
      "118 texts from path: data_selection/hatexplain_fp.csv\n",
      "XTREMESPEECH\n",
      "18 texts from path: data_selection/xtremespeech_fp.csv\n"
     ]
    }
   ],
   "source": [
    "# Import sampling dict with path and ids\n",
    "in_path = os.path.join('data_sampling', 'sampling.json')\n",
    "with open(in_path, 'r') as file:\n",
    "    sampling = json.load(file)\n",
    "for d_id, d_info in sampling.items():\n",
    "    print('{}'.format(d_id.upper()))\n",
    "    print('{} texts from path: {}'.format(len(d_info['ids']), d_info['path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_selection/mhs_fp.csv\n",
      "mhs all fps: (1789, 63)\n",
      "mhs sampled:  (130, 65) \n",
      "\n",
      "data_selection/gabhatecorpus_fp.csv\n",
      "gabhatecorpus all fps: (478, 28)\n",
      "gabhatecorpus sampled:  (84, 30) \n",
      "\n",
      "data_selection/hatexplain_fp.csv\n",
      "hatexplain all fps: (1303, 36)\n",
      "hatexplain sampled:  (118, 38) \n",
      "\n",
      "data_selection/xtremespeech_fp.csv\n",
      "xtremespeech all fps: (182, 34)\n",
      "xtremespeech sampled:  (18, 36) \n",
      "\n",
      "All data sampled: (350, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>predict_text</th>\n",
       "      <th>dataset</th>\n",
       "      <th>target_gso_Pred</th>\n",
       "      <th>target_gso_IRI</th>\n",
       "      <th>target_gso_Label</th>\n",
       "      <th>target_gso_Def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>my sister is very religious and waited until m...</td>\n",
       "      <td>mhs</td>\n",
       "      <td>0.851630</td>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_000381;htt...</td>\n",
       "      <td>lesbian;lesbian;marriage;lesbian identity;pers...</td>\n",
       "      <td>Typically, someone with a female gender identi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>888</td>\n",
       "      <td>no canadians wtf... you racist fuck go die in ...</td>\n",
       "      <td>mhs</td>\n",
       "      <td>0.557834</td>\n",
       "      <td>http://semanticscience.org/resource/SIO_000660...</td>\n",
       "      <td>hole;bitch;fuck</td>\n",
       "      <td>An aperture or hollow space within a solid mass.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id                                       predict_text dataset  \\\n",
       "0        303  my sister is very religious and waited until m...     mhs   \n",
       "1        888  no canadians wtf... you racist fuck go die in ...     mhs   \n",
       "\n",
       "   target_gso_Pred                                     target_gso_IRI  \\\n",
       "0         0.851630  http://purl.obolibrary.org/obo/GSSO_000381;htt...   \n",
       "1         0.557834  http://semanticscience.org/resource/SIO_000660...   \n",
       "\n",
       "                                    target_gso_Label  \\\n",
       "0  lesbian;lesbian;marriage;lesbian identity;pers...   \n",
       "1                                    hole;bitch;fuck   \n",
       "\n",
       "                                      target_gso_Def  \n",
       "0  Typically, someone with a female gender identi...  \n",
       "1   An aperture or hollow space within a solid mass.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add datasets seq\n",
    "data = []\n",
    "for dname in sampling.keys(): \n",
    "    path, ids = sampling[dname].values()\n",
    "    print(path)\n",
    "    df = pd.read_csv(path)\n",
    "    print(f'{dname} all fps:', df.shape)\n",
    "    df = df.loc[df['comment_id'].isin(ids),].reset_index()\n",
    "    df['dataset'] = [dname]*df.shape[0]\n",
    "    print(f'{dname} sampled: ', df.shape, '\\n')\n",
    "    data.append(df[cols_in])\n",
    "\n",
    "data = pd.concat(data, ignore_index=True)\n",
    "print(f'All data sampled: {data.shape}')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get already: comment ids, texts, match_entities_init\n",
    "comment_ids = data['comment_id'].to_list()\n",
    "texts = data['predict_text'].to_list()\n",
    "match_entities_init = data['target_gso_Label'].apply(lambda str: str.split(';')).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get entities and definitions\n",
    "\n",
    "export: 'data_preproc/1_defs.csv'\n",
    "\n",
    "Pipeline to get filter 1: \n",
    "- include target_gso_IRI \n",
    "- get their label and definition\n",
    "- order by label\n",
    "- export 4 col defs.csv to prune (xlsx tabs and then export pruned_concepts.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import kg\n",
    "def load_owl(path_to_owl_file: str):\n",
    "    \"\"\" load a local copy using owlready2 \"\"\"\n",
    "    from owlready2 import get_ontology\n",
    "    return get_ontology(path_to_owl_file).load()\n",
    "\n",
    "kg = load_owl('hate-speech-identities/models/adaptation/gsso.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kg_dict(kg, lang='en'):\n",
    "    \"\"\" Get dict of {k.iri: [label, synonym_1, syn_2, ... , syn_n]}\"\"\"\n",
    "    import owlready2\n",
    "    # Create dict from KG classess and inviduals\n",
    "    kg_cls_dict = {k.iri: k.label + k.alternateName + k.short_name + k.hasSynonym + k.hasExactSynonym +\n",
    "                   k.hasBroadSynonym + k.hasNarrowSynonym + k.hasRelatedSynonym + k.replaces + k.isReplacedBy\n",
    "                   for k in kg.classes()}\n",
    "    kg_ind_dict = {k.iri: k.label + k.alternateName + k.short_name + k.hasSynonym + k.hasExactSynonym +\n",
    "                   k.hasBroadSynonym + k.hasNarrowSynonym + k.hasRelatedSynonym + k.replaces + k.isReplacedBy\n",
    "                   for k in kg.individuals()}\n",
    "    kg_dict = {**kg_cls_dict, **kg_ind_dict}\n",
    "    # Filter only synonyms in English\n",
    "    def filter_by_lang(syns, lang):\n",
    "        return [syn for syn in syns if type(syn) == owlready2.util.locstr and syn.lang == lang]\n",
    "    kg_dict_en = {}\n",
    "    for c_iri, syns in kg_dict.items():\n",
    "        syns_en = filter_by_lang(syns, lang)\n",
    "        kg_dict_en[c_iri] = syns_en if len(syns_en) != 0 else syns\n",
    "    return kg_dict_en\n",
    "\n",
    "kg_dict = get_kg_dict(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts: 350\n",
      "['http://semanticscience.org/resource/SIO_000106', 'http://purl.obolibrary.org/obo/NCIT_C25172']\n",
      "vocabulary from unique entities matched: 724\n"
     ]
    }
   ],
   "source": [
    "match_iris_init = data['target_gso_IRI'].apply(lambda str: str.split(';')).to_list()\n",
    "print(f'Total texts: {len(match_iris_init)}')\n",
    "matched_iris = list(set([c_iri for c_iris in match_iris_init for c_iri in c_iris]))\n",
    "print(matched_iris[:2])\n",
    "print(f'vocabulary from unique entities matched: {len(matched_iris)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with corresponding labels: [['book', 'books', 'the book'], ['employment', 'employ', 'employed', 'employs']]\n"
     ]
    }
   ],
   "source": [
    "matched_label = [kg_dict[c_iri][0] for c_iri in matched_iris]\n",
    "matched_labels = [kg_dict[c_iri] for c_iri in matched_iris]\n",
    "print(f'with corresponding labels: {matched_labels[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with corresponding definitions: ['A book is a publication composed of a large number of entries.', 'The state of being engaged in an activity or service for wages or salary; the occupation for which you are paid.']\n"
     ]
    }
   ],
   "source": [
    "def get_definition(c_iri: owlready2.entity, kg: owlready2.namespace.Ontology):\n",
    "    \"\"\" get value of definition properity from k.iri \"\"\"\n",
    "    from owlready2 import default_world\n",
    "    c = kg.search_one(iri=c_iri)\n",
    "    try:\n",
    "        r = list(default_world.sparql(\"\"\"\n",
    "                SELECT ?y\n",
    "                {   ?? obo:IAO_0000115 ?y\n",
    "                }\n",
    "                \"\"\", [c]))\n",
    "    except ValueError:\n",
    "        #print(c_iri)\n",
    "        r = []\n",
    "    definition = r[0][0] if len(r)>0 else []\n",
    "    return definition\n",
    "\n",
    "matched_defs = [get_definition(c_iri, kg) for c_iri in matched_iris]\n",
    "print(f'with corresponding definitions: {matched_defs[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of definitions to check: (724, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRI</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_012929</td>\n",
       "      <td>.gay</td>\n",
       "      <td>[.gay]</td>\n",
       "      <td>A top-level domain name. It was proposed in IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_012928</td>\n",
       "      <td>.lgbt</td>\n",
       "      <td>[.lgbt]</td>\n",
       "      <td>A sponsored top-level domain for the LGBTQIA+ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>http://purl.obolibrary.org/obo/CHEBI_1391</td>\n",
       "      <td>3,4-methylenedioxymethamphetamine</td>\n",
       "      <td>[3,4-methylenedioxymethamphetamine, MDMA, N-Me...</td>\n",
       "      <td>A member of the class of benzodioxoles that is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_009887</td>\n",
       "      <td>4-real</td>\n",
       "      <td>[4-real]</td>\n",
       "      <td>An adjective referring to an individual as gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_010081</td>\n",
       "      <td>A-Gay</td>\n",
       "      <td>[A-Gay, A-Gays, A-List Gay, A-list gay, 'A' ga...</td>\n",
       "      <td>The gay elite; the class of gay people conside...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            IRI  \\\n",
       "487  http://purl.obolibrary.org/obo/GSSO_012929   \n",
       "91   http://purl.obolibrary.org/obo/GSSO_012928   \n",
       "532   http://purl.obolibrary.org/obo/CHEBI_1391   \n",
       "611  http://purl.obolibrary.org/obo/GSSO_009887   \n",
       "239  http://purl.obolibrary.org/obo/GSSO_010081   \n",
       "\n",
       "                                 Label  \\\n",
       "487                               .gay   \n",
       "91                               .lgbt   \n",
       "532  3,4-methylenedioxymethamphetamine   \n",
       "611                             4-real   \n",
       "239                              A-Gay   \n",
       "\n",
       "                                                Labels  \\\n",
       "487                                             [.gay]   \n",
       "91                                             [.lgbt]   \n",
       "532  [3,4-methylenedioxymethamphetamine, MDMA, N-Me...   \n",
       "611                                           [4-real]   \n",
       "239  [A-Gay, A-Gays, A-List Gay, A-list gay, 'A' ga...   \n",
       "\n",
       "                                                   Def  \n",
       "487  A top-level domain name. It was proposed in IC...  \n",
       "91   A sponsored top-level domain for the LGBTQIA+ ...  \n",
       "532  A member of the class of benzodioxoles that is...  \n",
       "611  An adjective referring to an individual as gen...  \n",
       "239  The gay elite; the class of gay people conside...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First filter: check labels and their meaning in context.\n",
    "def add_to_df(keys, values):\n",
    "    \"\"\" add values recursively to df keys \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for k,v in zip(keys, values):\n",
    "        df[k]= v\n",
    "    return df\n",
    "\n",
    "defs_info = {'IRI':matched_iris, 'Label': matched_label, 'Labels': matched_labels, 'Def': matched_defs}\n",
    "defs = add_to_df(defs_info.keys(), defs_info.values())\n",
    "\n",
    "defs.sort_values('Label', inplace=True)\n",
    "defs.to_csv(os.path.join(out_path, '1_defs.csv'), index=False)\n",
    "print(f'Number of definitions to check: {defs.shape}')\n",
    "defs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matching whole kg\n",
    "\n",
    "export: 'data_preproc/2_defs2complete.csv'\n",
    "\n",
    "Pipeline to get filter 2: \n",
    "- preprocess texts and kg_dict values (label and synonyms)\n",
    "- position matching the full kg\n",
    "- export 4 col defs2complete.csv to prune also non- or negative weighted entities ('Added' in defs.xlsx).\n",
    "\n",
    "These are only added to the hyperlinking (see sec. 6), and manually added to box entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmatize texts\n",
      "my sister is very religious and waited until marriage. she just celebrated her 5 year anniversary. she knew when i lost my virginity at 16 and never judged me. i had a baby that was fatherless last year and she is a proud aunt. she also attended her lesbian friend from high schools wedding last year. i wish more religious people were like that\n",
      "['my', 'sister', 'is', 'veri', 'religi', 'and', 'wait', 'until', 'marriag', 'she', 'just', 'celebrat', 'her', '5', 'year', 'anniversari', 'she', 'knew', 'when', 'i', 'lost', 'my', 'virgin', 'at', '16', 'and', 'never', 'judg', 'me', 'i', 'had', 'a', 'babi', 'that', 'wa', 'fatherless', 'last', 'year', 'and', 'she', 'is', 'a', 'proud', 'aunt', 'she', 'also', 'attend', 'her', 'lesbian', 'friend', 'from', 'high', 'school', 'wedd', 'last', 'year', 'i', 'wish', 'more', 'religi', 'peopl', 'were', 'like', 'that']\n",
      "stemmatize entity syns\n",
      "['penile agenesis', 'agenesis of the penis', 'penis agenesis', 'absent penis', 'aphallia', 'aphallus', 'aplasia of the penis', 'congenital absence and aplasia of penis', 'congenital absence of penis']\n",
      "['aphallia', 'agenesi of the peni', 'aphallu', 'absent peni', 'congenit absenc of peni', 'peni agenesi', 'aplasia of the peni', 'congenit absenc and aplasia of peni', 'penil agenesi']\n"
     ]
    }
   ],
   "source": [
    "# get stemma (including Stopwords)\n",
    "def stemmatize(text: str):\n",
    "    \"\"\" tokenize, lower-case, and stem filter using whoosh library \"\"\"\n",
    "    from whoosh.analysis import StemmingAnalyzer\n",
    "    stemmer = StemmingAnalyzer(stoplist=None) \n",
    "    return [token.text for token in stemmer(text)]\n",
    "\n",
    "# on texts from csv \n",
    "print('stemmatize texts')\n",
    "print(texts[0])\n",
    "stem_texts = [stemmatize(text) for text in texts]\n",
    "print(stem_texts[0])\n",
    "\n",
    "# on kg\n",
    "print('stemmatize entity syns')\n",
    "print(kg_dict['http://purl.bioontology.org/ontology/MESH/C536649'])\n",
    "stem_kg = {}\n",
    "for iri, syns in kg_dict.items():\n",
    "    stem_syns = list(set([' '.join(stemmatize(syn)) for syn in syns if type(syn) == owlready2.util.locstr]))\n",
    "    stem_kg[iri] = stem_syns\n",
    "print(stem_kg['http://purl.bioontology.org/ontology/MESH/C536649'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: ['United States', 'US', 'United States of America']\n",
      "Stemma: ['us', 'unit state', 'unit state of america']\n"
     ]
    }
   ],
   "source": [
    "# E.g.\n",
    "print('Entity: {}'.format(kg_dict['http://purl.bioontology.org/ontology/MESH/D014481']))\n",
    "print('Stemma: {}'.format(stem_kg['http://purl.bioontology.org/ontology/MESH/D014481']))\n",
    "# ... if stopwords were removed, 'US' would be ' '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'sister', 'is', 'veri', 'religi', 'and', 'wait', 'until', 'marriag', 'she', 'just', 'celebrat', 'her', '5', 'year', 'anniversari', 'she', 'knew', 'when', 'i', 'lost', 'my', 'virgin', 'at', '16', 'and', 'never', 'judg', 'me', 'i', 'had', 'a', 'babi', 'that', 'wa', 'fatherless', 'last', 'year', 'and', 'she', 'is', 'a', 'proud', 'aunt', 'she', 'also', 'attend', 'her', 'lesbian', 'friend', 'from', 'high', 'school', 'wedd', 'last', 'year', 'i', 'wish', 'more', 'religi', 'peopl', 'were', 'like', 'that']\n",
      "All entities in kg: 16084\n",
      "16084\n",
      "error in tim\n",
      "  label  tim\n",
      "imrankhan ha an overwhelm goodwil internation bangladesh s pm hasina wajid is known for her anti pakistan postur yet she activ engag with ik at the oicmakkahsummit ik also had a posit meet with ashraf ghani.tim for better relat with neighbour url\n",
      "error in child\n",
      "  label  children\n",
      "i am not marri to a diplmat nor a trail spous i have had sever job around the globe as well as a singl mother of an austic child.i us to live in hanoi for a few year too i love laura s talk she s do her thing and shouldn t be judg and no on should ever assum thei cannot achiev anyth live your dream and be kind\n",
      "error in l\n",
      "  label  lesbian\n",
      "liter all you gotta do is look at aoc listen to her talk youll know she is bat shit insan then listen to how the muslim rag head bitch marri her own brother to know thi whollleee countri is fuck h.o.l.i fuck\n",
      "error in i\n",
      "  label  indetermin sex and pseudohermaphrodit\n",
      "liter all you gotta do is look at aoc listen to her talk youll know she is bat shit insan then listen to how the muslim rag head bitch marri her own brother to know thi whollleee countri is fuck h.o.l.i fuck\n",
      "error in i\n",
      "  label  i\n",
      "liter all you gotta do is look at aoc listen to her talk youll know she is bat shit insan then listen to how the muslim rag head bitch marri her own brother to know thi whollleee countri is fuck h.o.l.i fuck\n",
      "error in www\n",
      "  label  web\n",
      "http www.youtube.com watch v kwwzcrsqojq t liber attack queer eye star for tweet all republican ar not racist\n",
      "error in li\n",
      "  label  li\n",
      "chicago cardin global warm migrant ar bigger agenda than sex abus http bit.li 2btfjcf via breitbartnew wai to deflect those accus\n",
      "error in www\n",
      "  label  web\n",
      "swedish femal learn that someon is to be deport to afghanistan bui a ticket for the same flight and refus to sit down so that the pilot can t take off until the would be deporte is remov from the plane she succe surround peopl listen to her and bend to her will defi proper procedur is thi the futur http www.youtube.com watch v dhz4zggo53u\n",
      "error in www\n",
      "  label  web\n",
      "or how about thi stop send your kid to these bullshit marxist indoctrin academi http www.foxnews.com us 2018 03 02 pronoun matt\n",
      "error in www\n",
      "  label  web\n",
      "haha joi reid step in shit as she get bust make libtard trigger anti gai comment becaus she doesn t know how to spell feud http www.infowars.com bust joi reid misspel suggest she did write homophob blog post\n",
      "error in u\n",
      "  label  not differentiat\n",
      "2030 a glimps april is set to becom anal sex month in the u. after a joint resolut proclaim so sail through both hous earlier todai mani lawmak express disappoint that pedo week legisl is for now on hold as freedom caucu member threaten a filibust cite state right as their onli object cantwel pnn\n",
      "error in u\n",
      "  label  not differentiat\n",
      "will the cowardli littl nazi faggot that downvot u. marin kindli identifi yourself so we can all mock you thank you\n",
      "error in e\n",
      "  label  e\n",
      "an academ dwarf like oscar sudi should be the last to lectur h.e dr kalonzo musyoka on matter polit you and your master ar a real definit of a thief and that is what you ar call kalonzo poor and good in dye hi hair sound empti and flat oscar kipchumba sudi you should also know that your dental formular of 50 big teeth doe not give you the permiss to mouth diarrhea aimlessli close your dirti mouth and engag your equal\n",
      "error in e\n",
      "  label  e\n",
      "an academ dwarf like oscar sudi should be the last to lectur h.e dr kalonzo musyoka on matter polit you and your master ar a real definit of a thief and that is what you ar call kalonzo poor and good in dye hi hair sound empti and flat oscar kipchumba sudi you should also know that your dental formular of 50 big teeth doe not give you the permiss to mouth diarrhea aimlessli close your dirti mouth and engag your equal\n"
     ]
    }
   ],
   "source": [
    "# position matching (compute time: 15m 31s)\n",
    "def matching(src, dest):\n",
    "    \"\"\" Export entities whose dict value matches the text. Returns list of entities (i.e, dict keys) and labels \"\"\"\n",
    "    import re\n",
    "    match_URLs = [0]*len(dest)\n",
    "    match_entities, mismatch_entities = [0]*len(dest), []\n",
    "    for URL, v in src.items():\n",
    "        for vi in v: \n",
    "            # 1.Is it a match? Full text with the stem syns\n",
    "            if isinstance(vi, owlready2.entity.Thing) or isinstance(vi, owlready2.entity.ThingClass): # if entity, take its label\n",
    "                vi = vi.label[0]\n",
    "            # 2. only if string appears in text, get index\n",
    "            if (isinstance(vi, owlready2.util.locstr) or isinstance(vi, str)) and vi != '':  \n",
    "                if re.search(r\"\\b\" + re.escape(vi) + r\"\\b\", ' '.join(dest)):\n",
    "                    vi_0 = vi.split(' ')[0]\n",
    "                    try:\n",
    "                        idx = dest.index(vi_0)\n",
    "                        # 3. Add URL if empty position, else add to mismatches\n",
    "                        if match_URLs[idx] == 0:\n",
    "                            match_URLs[idx] = URL\n",
    "                            match_entities[idx] = v[0]\n",
    "                        else:\n",
    "                            mismatch_entities.append(v[0])\n",
    "                        break\n",
    "                    except ValueError: # e.g. when entity in '.entity'\n",
    "                        print(f'error in {vi}')\n",
    "                        print('  label ',v[0])\n",
    "                        print(' '.join(dest))\n",
    "                        mismatch_entities.append(v[0])\n",
    "\n",
    "    return match_URLs, match_entities, mismatch_entities \n",
    "\n",
    "print(stem_texts[0])\n",
    "match_URLs_all = []\n",
    "# link only the ones with definitions (and found with neg weights)\n",
    "print(f'All entities in kg: {len(stem_kg.keys())}')\n",
    "print(len(stem_kg.keys()))\n",
    "for i, stem_text in enumerate(stem_texts):\n",
    "    match_URLs_i, _, _ = matching(stem_kg, stem_text)\n",
    "    match_URLs_all.append(match_URLs_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities found from stem kg: 596\n",
      "entities that were not in the definition list (1_defs.csv): 61\n"
     ]
    }
   ],
   "source": [
    "# Second filter: check entities not weighted by the model or with negative weights.\n",
    "matched_iris_all = list(set([url for urls in match_URLs_all for url in urls if url!=0]))\n",
    "print(f'entities found from stem kg: {len(matched_iris_all)}')\n",
    "matched_iris_all = [iri2check for iri2check in matched_iris_all if iri2check not in defs['IRI'].to_list()]\n",
    "print(f'entities that were not in the definition list (1_defs.csv): {len(matched_iris_all)}')\n",
    "matched_label_all = [stem_kg[iri][0] for iri in matched_iris_all]\n",
    "matched_labels_all = [stem_kg[iri] for iri in matched_iris_all]\n",
    "matched_defs_all = [get_definition(c_iri, kg) for c_iri in matched_iris_all]\n",
    "\n",
    "defs2complete_info = {'IRI':matched_iris_all, 'Label': matched_label_all, 'Labels': matched_labels_all, 'Def': matched_defs_all}\n",
    "defs2complete = add_to_df(defs2complete_info.keys(), defs2complete_info.values())\n",
    "\n",
    "defs2complete.sort_values('Label', inplace=True)\n",
    "defs2complete.to_csv(os.path.join(out_path, '2_defs2complete.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Manual prunning of definitions\n",
    "\n",
    "export: 'data_preproc/pruned_concepts.csv'\n",
    "\n",
    "Codes in 1_defs.csv (filter 1):\n",
    "- Repeated: same matching labels (duplicated with more relevant entity)\n",
    "- Abbr: incorrectly matched by its abbreviations\n",
    "- IR: not relevant to LGBTQ (too general)\n",
    "- UN: [undefined entity and not relevant]\n",
    "\n",
    "We get 181 from 724 definitions.\n",
    "\n",
    "Codes in 2_defs2complete.csv (filter 2):\n",
    "- Added: non-weighted or with negative weights \n",
    "- Added (manual final check) >> found when revising the texts.\n",
    "\n",
    "We get 12 from 61 definitions (+ 11 that are manually added, see sec 6)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Box definitions \n",
    "\n",
    "Add: (box_entities, box_defs)\n",
    "\n",
    "Box_entities (string by commas) and box_defs from match_entities_init if in 'pruned_concepts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRI</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Def</th>\n",
       "      <th>Pruned</th>\n",
       "      <th>Modified</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_000137</td>\n",
       "      <td>LGBT</td>\n",
       "      <td>['LGBT', 'LBGT', 'lesbian, gay, bisexual and t...</td>\n",
       "      <td>An initialism for lesbian, gay, bisexual, tran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://purl.obolibrary.org/obo/GSSO_000586</td>\n",
       "      <td>LGBTQ</td>\n",
       "      <td>['LGBTQ', 'LGBTQ+', 'lesbian, gay, bisexual, t...</td>\n",
       "      <td>An initialism standing for lesbian, gay, bisex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          IRI  Label  \\\n",
       "0  http://purl.obolibrary.org/obo/GSSO_000137   LGBT   \n",
       "1  http://purl.obolibrary.org/obo/GSSO_000586  LGBTQ   \n",
       "\n",
       "                                              Labels  \\\n",
       "0  ['LGBT', 'LBGT', 'lesbian, gay, bisexual and t...   \n",
       "1  ['LGBTQ', 'LGBTQ+', 'lesbian, gay, bisexual, t...   \n",
       "\n",
       "                                                 Def Pruned Modified  \\\n",
       "0  An initialism for lesbian, gay, bisexual, tran...    NaN      NaN   \n",
       "1  An initialism standing for lesbian, gay, bisex...    NaN      NaN   \n",
       "\n",
       "  Unnamed: 6  \n",
       "0        NaN  \n",
       "1        NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defs_pruned = pd.read_csv(os.path.join('pruned_concepts.csv'))\n",
    "print(defs_pruned.shape)\n",
    "defs_pruned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesbian;lesbian;marriage;lesbian identity;person;lesbianism;friend;pibling;sibling;wedding;hers;her;she;sexual abstinence;anniversary;religious person;religion;year;justice;myalgic encephalomyelitis;me;her'n\n",
      "\n",
      "Example after filtering definitions\n",
      "['lesbian', 'marriage', 'pibling', 'sibling', 'her', 'she', 'sexual abstinence']\n",
      "['A sexual orientation describing someone with a female gender identity who is attracted to those with female gender identities, or attraction to those identifying within a feminine gender-area (including transfeminine persons, femme nonbinary people, nonbinary women, demigirls, etc.).', 'A culturally recognized union between people, called spouses. The definition of marriage varies around the world, not only between cultures and between religions, but also throughout the history of any given culture and religion. ', 'A sibling of a parent.', 'A person who shares a parent.', 'To refer to a woman, girl, or female animal that has just been mentioned or is just about to be mentioned:', 'Used as the subject of a verb to refer to a woman, girl, or female animal that has already been mentioned:', 'Refraining from sexual intercourse for any reason.']\n"
     ]
    }
   ],
   "source": [
    "# Include entity label and definitions from the pruned list\n",
    "print(data['target_gso_Label'].to_list()[0])\n",
    "box_entities, box_defs, box_iris = [], [], []\n",
    "for match_iri in match_iris_init:\n",
    "    box_iri = [iri for iri in match_iri if iri in defs_pruned['IRI'].to_list()]\n",
    "    box_iris.append(box_iri)\n",
    "\n",
    "    box_entity = [defs_pruned.loc[defs_pruned.IRI==iri, 'Label'].values[0] for iri in box_iri]\n",
    "    box_entities.append(box_entity)\n",
    "    \n",
    "    box_def = [defs_pruned.loc[defs_pruned.IRI==iri, 'Def'].values[0] for iri in box_iri]\n",
    "    box_defs.append(box_def)\n",
    "print('\\nExample after filtering definitions')\n",
    "print(box_entities[0])\n",
    "print(box_defs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperlinking\n",
    "\n",
    "Add: (stem_text, match_URLs, match_entities, mismatch_entities) \n",
    "\n",
    "Match_URLs (string list) from kg stemma [of entities in box definitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entities in kg: 16084\n",
      "including only the ones defined: 193\n"
     ]
    }
   ],
   "source": [
    "# Position matching with kg stemma of only matched+selected entities (comp. time: 12s). \n",
    "match_URLs, match_entities, mismatch_entities = [], [], []\n",
    "# link only the ones with definitions (and found with neg weights)\n",
    "print(f'All entities in kg: {len(stem_kg.keys())}')\n",
    "selected_stem_kg = {iri: stem_kg[iri] for iri in defs_pruned['IRI']}\n",
    "print(f'including only the ones defined: {len(selected_stem_kg.keys())}')\n",
    "for i, stem_text in enumerate(stem_texts):\n",
    "    match_URLs_i, match_entities_i, mismatch_entities_i = matching(selected_stem_kg, stem_text)\n",
    "    match_URLs.append(match_URLs_i)\n",
    "    match_entities.append(match_entities_i)\n",
    "    mismatch_entities.append(mismatch_entities_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export data\n",
    "\n",
    "export: 'data_preproc/4_sample.csv'\n",
    "\n",
    "Manual checks in sample_final.xlsx\n",
    "- utf: Removed wrong encoded chars\n",
    "- delete: Removed non defined or other meanings in context.\n",
    "- abbr/remove: delete from box (other meanings or abbr)\n",
    "- in-cont: change defs to fit in context\n",
    "- missing: marked defs to check if in kg, completed with external sources.\n",
    "\n",
    "To round up: less relevant (only pronouns, or repeated insults like bitch, not intilligible bc removed wrong encoded characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE:\n",
      "['my', 'sister', 'is', 'veri', 'religi', 'and', 'wait', 'until', 'marriag', 'she', 'just', 'celebrat', 'her', '5', 'year', 'anniversari', 'she', 'knew', 'when', 'i', 'lost', 'my', 'virgin', 'at', '16', 'and', 'never', 'judg', 'me', 'i', 'had', 'a', 'babi', 'that', 'wa', 'fatherless', 'last', 'year', 'and', 'she', 'is', 'a', 'proud', 'aunt', 'she', 'also', 'attend', 'her', 'lesbian', 'friend', 'from', 'high', 'school', 'wedd', 'last', 'year', 'i', 'wish', 'more', 'religi', 'peopl', 'were', 'like', 'that']\n",
      "\n",
      "ENRICHED TEXT:\n",
      "my ![sister](http://purl.obolibrary.org/obo/GSSO_001955) is veri religi and wait until ![marriag](http://purl.obolibrary.org/obo/GSSO_003838) ![she](http://purl.obolibrary.org/obo/GSSO_002432) just celebrat ![her](http://purl.obolibrary.org/obo/GSSO_002437) 5 year anniversari she knew when i lost my ![virgin](http://purl.bioontology.org/ontology/MESH/D012746) at 16 and never judg me i had a babi that wa fatherless last year and she is a proud ![aunt](http://purl.obolibrary.org/obo/GSSO_001951) she also attend her ![lesbian](http://purl.obolibrary.org/obo/GSSO_011155) friend from high school wedd last year i wish more religi peopl were like that\n",
      "\n",
      "INFORMATION BOX:\n",
      "lesbian: A sexual orientation describing someone with a female gender identity who is attracted to those with female gender identities, or attraction to those identifying within a feminine gender-area (including transfeminine persons, femme nonbinary people, nonbinary women, demigirls, etc.).\n",
      "\n",
      "marriage: A culturally recognized union between people, called spouses. The definition of marriage varies around the world, not only between cultures and between religions, but also throughout the history of any given culture and religion. \n",
      "\n",
      "pibling: A sibling of a parent.\n",
      "\n",
      "sibling: A person who shares a parent.\n",
      "\n",
      "her: To refer to a woman, girl, or female animal that has just been mentioned or is just about to be mentioned:\n",
      "\n",
      "she: Used as the subject of a verb to refer to a woman, girl, or female animal that has already been mentioned:\n",
      "\n",
      "sexual abstinence: Refraining from sexual intercourse for any reason.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "print(f'EXAMPLE:\\n{stem_texts[0]}')\n",
    "print('\\nEnriched text:'.upper())\n",
    "text_example = ' '.join([f'![{e}]({URL})' if URL != 0 else e for e, URL in zip(stem_texts[0], match_URLs[0])])\n",
    "#display(Markdown(text_example))\n",
    "print(text_example)\n",
    "print('\\nInformation box:'.upper())\n",
    "for box_e, box_d in zip(box_entities[0], box_defs[0]):\n",
    "    print(f'{box_e}: {box_d}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 11)\n",
      "mhs              130\n",
      "hatexplain       118\n",
      "gabhatecorpus     84\n",
      "xtremespeech      18\n",
      "Name: dataset, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>box_entity</th>\n",
       "      <th>box_def</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>match_URLs</th>\n",
       "      <th>match_entities</th>\n",
       "      <th>mismatch_entities</th>\n",
       "      <th>match_entities_init</th>\n",
       "      <th>entity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mhs</td>\n",
       "      <td>303</td>\n",
       "      <td>my sister is very religious and waited until m...</td>\n",
       "      <td>[lesbian, marriage, pibling, sibling, her, she...</td>\n",
       "      <td>[A sexual orientation describing someone with ...</td>\n",
       "      <td>[my, sister, is, veri, religi, and, wait, unti...</td>\n",
       "      <td>[0, http://purl.obolibrary.org/obo/GSSO_001955...</td>\n",
       "      <td>[0, sibl, 0, 0, 0, 0, 0, 0, marriag, she, 0, 0...</td>\n",
       "      <td>[aunt]</td>\n",
       "      <td>[lesbian, lesbian, marriage, lesbian identity,...</td>\n",
       "      <td>lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mhs</td>\n",
       "      <td>888</td>\n",
       "      <td>no canadians wtf... you racist fuck go die in ...</td>\n",
       "      <td>[hole, bitch, fuck]</td>\n",
       "      <td>[An aperture or hollow space within a solid ma...</td>\n",
       "      <td>[no, canadian, wtf, you, racist, fuck, go, die...</td>\n",
       "      <td>[0, 0, 0, 0, 0, http://purl.obolibrary.org/obo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, f ck, 0, 0, 0, 0, hole, 0, bitch]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hole, bitch, fuck]</td>\n",
       "      <td>hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mhs</td>\n",
       "      <td>2040</td>\n",
       "      <td>fuck the queen, aborted that bitch in 1776</td>\n",
       "      <td>[abortion, bitch, fuck, queen]</td>\n",
       "      <td>[Abortion is the ending of pregnancy due to re...</td>\n",
       "      <td>[fuck, the, queen, abort, that, bitch, in, 1776]</td>\n",
       "      <td>[http://purl.obolibrary.org/obo/GSSO_004152, 0...</td>\n",
       "      <td>[f ck, 0, queeni, pregnanc with abort outcom, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[abortion, facesitting, bitch, fuck, queen]</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mhs</td>\n",
       "      <td>6425</td>\n",
       "      <td>&gt; i'm not focusing on one over the other. this...</td>\n",
       "      <td>[LGBT, feeling, queer, whataboutism]</td>\n",
       "      <td>[An initialism for lesbian, gay, bisexual, tra...</td>\n",
       "      <td>[i, m, not, focus, on, on, over, the, other, t...</td>\n",
       "      <td>[0, http://purl.obolibrary.org/obo/GSSO_000090...</td>\n",
       "      <td>[0, male, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[LGBT, .lgbt, r/lgbt, queer sexual orientation...</td>\n",
       "      <td>LGBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mhs</td>\n",
       "      <td>7769</td>\n",
       "      <td>shut yo bitch ass up nigga, you sound like you...</td>\n",
       "      <td>[bitch, fuck]</td>\n",
       "      <td>[A pejorative slang term usually used for a wo...</td>\n",
       "      <td>[shut, yo, bitch, ass, up, nigga, you, sound, ...</td>\n",
       "      <td>[0, 0, http://purl.obolibrary.org/obo/GSSO_003...</td>\n",
       "      <td>[0, 0, bitch, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[therapeutic procedure, sound, sounding, retro...</td>\n",
       "      <td>therapeutic procedure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset comment_id                                               text  \\\n",
       "0     mhs        303  my sister is very religious and waited until m...   \n",
       "1     mhs        888  no canadians wtf... you racist fuck go die in ...   \n",
       "2     mhs       2040         fuck the queen, aborted that bitch in 1776   \n",
       "3     mhs       6425  > i'm not focusing on one over the other. this...   \n",
       "4     mhs       7769  shut yo bitch ass up nigga, you sound like you...   \n",
       "\n",
       "                                          box_entity  \\\n",
       "0  [lesbian, marriage, pibling, sibling, her, she...   \n",
       "1                                [hole, bitch, fuck]   \n",
       "2                     [abortion, bitch, fuck, queen]   \n",
       "3               [LGBT, feeling, queer, whataboutism]   \n",
       "4                                      [bitch, fuck]   \n",
       "\n",
       "                                             box_def  \\\n",
       "0  [A sexual orientation describing someone with ...   \n",
       "1  [An aperture or hollow space within a solid ma...   \n",
       "2  [Abortion is the ending of pregnancy due to re...   \n",
       "3  [An initialism for lesbian, gay, bisexual, tra...   \n",
       "4  [A pejorative slang term usually used for a wo...   \n",
       "\n",
       "                                           stem_text  \\\n",
       "0  [my, sister, is, veri, religi, and, wait, unti...   \n",
       "1  [no, canadian, wtf, you, racist, fuck, go, die...   \n",
       "2   [fuck, the, queen, abort, that, bitch, in, 1776]   \n",
       "3  [i, m, not, focus, on, on, over, the, other, t...   \n",
       "4  [shut, yo, bitch, ass, up, nigga, you, sound, ...   \n",
       "\n",
       "                                          match_URLs  \\\n",
       "0  [0, http://purl.obolibrary.org/obo/GSSO_001955...   \n",
       "1  [0, 0, 0, 0, 0, http://purl.obolibrary.org/obo...   \n",
       "2  [http://purl.obolibrary.org/obo/GSSO_004152, 0...   \n",
       "3  [0, http://purl.obolibrary.org/obo/GSSO_000090...   \n",
       "4  [0, 0, http://purl.obolibrary.org/obo/GSSO_003...   \n",
       "\n",
       "                                      match_entities mismatch_entities  \\\n",
       "0  [0, sibl, 0, 0, 0, 0, 0, 0, marriag, she, 0, 0...            [aunt]   \n",
       "1  [0, 0, 0, 0, 0, f ck, 0, 0, 0, 0, hole, 0, bitch]                []   \n",
       "2  [f ck, 0, queeni, pregnanc with abort outcom, ...                []   \n",
       "3  [0, male, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                []   \n",
       "4  [0, 0, bitch, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...                []   \n",
       "\n",
       "                                 match_entities_init              entity_id  \n",
       "0  [lesbian, lesbian, marriage, lesbian identity,...                lesbian  \n",
       "1                                [hole, bitch, fuck]                   hole  \n",
       "2        [abortion, facesitting, bitch, fuck, queen]               abortion  \n",
       "3  [LGBT, .lgbt, r/lgbt, queer sexual orientation...                   LGBT  \n",
       "4  [therapeutic procedure, sound, sounding, retro...  therapeutic procedure  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_ids = [matches[0] for matches in match_entities_init]\n",
    "sample_data = [data['dataset'], comment_ids, texts, box_entities, box_defs, stem_texts, \n",
    "    match_URLs, match_entities, mismatch_entities, match_entities_init, entity_ids]\n",
    "\n",
    "sample = add_to_df(cols_out, sample_data)\n",
    "print(sample.shape)\n",
    "# only publish ids (protection of 18 xtremespeech texts)\n",
    "sample.drop(columns=['text']).to_csv(os.path.join(out_path, '4_sample.csv'), index=False)\n",
    "\n",
    "print(sample.dataset.value_counts())\n",
    "sample.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
